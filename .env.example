# ===== Paths =====
LITGRAPH_DATA_DIR=../DATA          # Default: DATA/ alongside repo root, absolute or relative

# ===== LLM Mode =====
LITGRAPH_MODE=pro                   # pro | lite

# ===== Pro Mode (Claude subscription via proxy) =====
LITGRAPH_PROXY_BASE_URL=http://localhost:3456/v1
LITGRAPH_PROXY_API_KEY=not-needed
LITGRAPH_PRO_BEST_MODEL=claude-sonnet-4
LITGRAPH_PRO_CHEAP_MODEL=claude-haiku-4

# ===== Lite Mode (local Ollama) =====
LITGRAPH_OLLAMA_BASE_URL=http://localhost:11434/v1
LITGRAPH_OLLAMA_MODEL=qwen2.5:7b    # or llama3.1:8b, gemma2:9b, etc.

# ===== Embedding (shared by both modes) =====
LITGRAPH_EMBEDDING_MODEL=all-MiniLM-L6-v2

# ===== Retry & Rate Limiting (global) =====
LITGRAPH_MAX_RETRIES=3              # Max retries for LLM / search API calls
LITGRAPH_RETRY_BACKOFF_BASE=2.0     # Exponential backoff base (seconds), wait = base^attempt
LITGRAPH_SEARCH_RATE_LIMIT=90       # Semantic Scholar max requests per window (official limit 100)
LITGRAPH_SEARCH_RATE_PERIOD=300     # Rate limit window (seconds), default 5 minutes
