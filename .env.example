# ===== Paths =====
LITGRAPH_DATA_DIR=../DATA          # Default: DATA/ alongside repo root, absolute or relative

# ===== LLM Mode =====
LITGRAPH_MODE=pro                   # pro | lite

# ===== Pro Mode (Anthropic API - direct connection) =====
# Supports both OAuth subscription tokens and standard API keys:
#   - OAuth token (sk-ant-oat01-...): Uses Authorization: Bearer header
#   - API key (sk-ant-api03-...): Uses x-api-key header
# Priority: ANTHROPIC_OAUTH_TOKEN > LITGRAPH_ANTHROPIC_API_KEY > ANTHROPIC_API_KEY
LITGRAPH_ANTHROPIC_API_KEY=         # Your Anthropic API key or OAuth token
LITGRAPH_PRO_BEST_MODEL=claude-sonnet-4-20250514
LITGRAPH_PRO_CHEAP_MODEL=claude-haiku-4-20250414

# ===== Lite Mode (local Ollama) =====
LITGRAPH_OLLAMA_BASE_URL=http://localhost:11434/v1
LITGRAPH_OLLAMA_MODEL=qwen2.5:7b    # or llama3.1:8b, gemma2:9b, etc.

# ===== Embedding (shared by both modes) =====
LITGRAPH_EMBEDDING_MODEL=all-MiniLM-L6-v2

# ===== Retry & Rate Limiting (global) =====
LITGRAPH_MAX_RETRIES=3              # Max retries for LLM / search API calls
LITGRAPH_RETRY_BACKOFF_BASE=2.0     # Exponential backoff base (seconds), wait = base^attempt
LITGRAPH_SEARCH_RATE_LIMIT=90       # Semantic Scholar max requests per window (official limit 100)
LITGRAPH_SEARCH_RATE_PERIOD=300     # Rate limit window (seconds), default 5 minutes
